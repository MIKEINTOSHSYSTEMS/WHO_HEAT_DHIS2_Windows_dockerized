<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Dataset on Situation Awareness and Task Performance...</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body><div class="container">

<table width="100%" summary="page for dat.bakdash2021 {metadat}"><tr><td>dat.bakdash2021 {metadat}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>Dataset on Situation Awareness and Task Performance Associations</h2>

<h3>Description</h3>

<p>Results from 77 papers with 678 effects evaluating associations among measures of situation awareness and task performance.</p>


<h3>Usage</h3>

<pre>
dat.bakdash2021
</pre>


<h3>Format</h3>

<p>The data frame contains the following columns:
</p>

<table summary="Rd table">
<tr>
 <td style="text-align: left;">
<b>Author</b>            </td><td style="text-align: left;"> <code>character</code> </td><td style="text-align: left;"> paper author(s) </td>
</tr>
<tr>
 <td style="text-align: left;">
<b>Year</b>              </td><td style="text-align: left;"> <code>integer</code>   </td><td style="text-align: left;"> year of paper publication </td>
</tr>
<tr>
 <td style="text-align: left;">
<b>Title</b>             </td><td style="text-align: left;"> <code>character</code> </td><td style="text-align: left;"> title of paper </td>
</tr>
<tr>
 <td style="text-align: left;">
<b>DOI</b>               </td><td style="text-align: left;"> <code>character</code> </td><td style="text-align: left;"> digital object identifier (DOI) </td>
</tr>
<tr>
 <td style="text-align: left;">
<b>DTIC.link</b>         </td><td style="text-align: left;"> <code>character</code> </td><td style="text-align: left;"> permanent link for Defense Technical Information Collection (DITC) reports; see: <code style="white-space: pre;">https://www.dtic.mil</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
<b>SA.measure.type</b>   </td><td style="text-align: left;"> <code>character</code> </td><td style="text-align: left;"> type of SA measure </td>
</tr>
<tr>
 <td style="text-align: left;">
<b>Sample.size</b>       </td><td style="text-align: left;"> <code>integer</code>   </td><td style="text-align: left;"> reported sample size </td>
</tr>
<tr>
 <td style="text-align: left;">
<b>Sample.size.stats</b> </td><td style="text-align: left;"> <code>integer</code>   </td><td style="text-align: left;"> reported sample size based on reported statistics (this reflects excluded participants) </td>
</tr>
<tr>
 <td style="text-align: left;">
<b>es.z</b>              </td><td style="text-align: left;"> <code>numeric</code>   </td><td style="text-align: left;"> z-transformed correlation coefficient; includes ghost results (disclosed and undisclosed non-significant effects not reported in detail) imputed using the draw method described in Bakdash et al. (2021a) </td>
</tr>
<tr>
 <td style="text-align: left;">
<b>vi.z</b>              </td><td style="text-align: left;"> <code>numeric</code>   </td><td style="text-align: left;"> variance for z-transformed correlation (calculated using <code>Sample.size.stats</code>, <em>not</em> <code>Sample.size</code>) </td>
</tr>
<tr>
 <td style="text-align: left;">
<b>SampleID</b>          </td><td style="text-align: left;"> <code>character</code> </td><td style="text-align: left;"> unique identifier for each experiment/study </td>
</tr>
<tr>
 <td style="text-align: left;">
<b>Outcome</b>           </td><td style="text-align: left;"> <code>integer</code>   </td><td style="text-align: left;"> unique value for each effect size
</td>
</tr>

</table>



<h3>Details</h3>

<p>The dataset contains behavioral experiments from 77 papers/79 studies with a total of 678 effects, evaluating associations among measures of situation awareness (&ldquo;knowing what is going on&rdquo;) and task performance. Examples of situation awareness include knowledge of current vehicle speed in a simulated driving task and location and heading of aircraft in a simulated air traffic control task. Corresponding examples of task performance include &ldquo;the number of collisions in a simulated driving task&rdquo; and &ldquo;subject matter expert rating of conflict management in a simulated air control task&rdquo; (Bakdash et al. 2021a, p. 2). This dataset and the &lsquo;Examples&rsquo; are a highly simplified version of the data and code in Bakdash et al. (2021b; 2021c). The journal article by Bakdash et al. (2021a) describes the systematic review and meta-analysis in detail.
</p>
<p>This dataset is used to illustrate multilevel multivariate meta-analytic models for the overall pooled effect and pooled effects by situation awareness measure. We also adjust meta-analytic models using cluster-robust variance estimation / cluster-robust inference with the <code><a href="../../metafor/help/robust.html">robust</a></code> function in <em>metafor</em>. Results are shown graphically in a customized forest plot with a prediction interval (estimated plausible range of individual effects). Last, we create a table summarizing the estimated meta-analytic heterogeneity parameters.
</p>
<p>The meta-analytic results show most pooled effect sizes in the positive medium range or less. There was also substantial meta-analytic heterogeneity (estimated systematic variance in true effects), nearing the magnitude of the overall pooled effect. We interpret the meta-analytic results as situation awareness typically having limited validity for task performance (i.e., good situation awareness does not tend to have strong probabilistic links with good performance and vice-versa). More formally, measures of situation awareness do not generally and meaningfully capture cognitive processes and other relevant factors underlying task performance.
</p>


<h4>Run-Time</h4>

<p>The code run-time can be greatly sped-up using a linear algebra library with <em>R</em> that makes use of multiple CPU cores. See: <a href="https://www.metafor-project.org/doku.php/tips:speeding_up_model_fitting">https://www.metafor-project.org/doku.php/tips:speeding_up_model_fitting</a>. To measure the run-time, uncomment these three lines: <code>start.time &lt;- Sys.time()</code>, <code>end.time &lt;- Sys.time()</code>, and <code>end.time - start.time</code>. Run-times on Windows 10 x64 with the Intel Math Kernel Library are:
</p>

<table summary="Rd table">
<tr>
 <td style="text-align: right;">
   </td><td style="text-align: left;"> <em>CPU</em> </td><td style="text-align: left;"> <em>Run-Time (Minutes)</em> </td>
</tr>
<tr>
 <td style="text-align: right;">
   </td><td style="text-align: left;"> i7-11850H  </td><td style="text-align: left;"> 2.49 </td>
</tr>
<tr>
 <td style="text-align: right;">
   </td><td style="text-align: left;"> i7-4770    </td><td style="text-align: left;"> 5.38 </td>
</tr>
<tr>
 <td style="text-align: right;">
   </td>
</tr>

</table>




<h3>Concepts</h3>

<p>psychology, human factors, engineering, correlation coefficients, multilevel models, multivariate models, cluster-robust inference
</p>


<h3>Author(s)</h3>

<p>Jonathan Bakdash, <a href="mailto:jonathan.z.bakdash.civ@army.mil">jonathan.z.bakdash.civ@army.mil</a>, <a href="mailto:jbakdash@gmail.com">jbakdash@gmail.com</a> <br />
Laura Marusich, <a href="mailto:laura.m.cooper20.civ@army.mil">laura.m.cooper20.civ@army.mil</a>, <a href="mailto:lmarusich@gmail.com">lmarusich@gmail.com</a>
</p>


<h3>Source</h3>

<p>Bakdash, J. Z., Marusich, L. R., Cox, K. R., Geuss, M. N., Zaroukian, E. G., &amp; Morris, K. M. (2021b). The validity of situation awareness for performance: A meta-analysis (Code Ocean Capsule). <code style="white-space: pre;">https://doi.org/10.24433/CO.1682542.v4</code>
</p>
<p>Bakdash, J. Z., Marusich, L. R., Cox, K. R., Geuss, M. N., Zaroukian, E. G., &amp; Morris, K. M. (2021c). The validity of situation awareness for performance: A meta-analysis (Systematic Review, Data, and Code). <code style="white-space: pre;">https://doi.org/10.17605/OSF.IO/4K7ZV</code>
</p>


<h3>References</h3>

<p>Bakdash, J. Z., Marusich, L. R., Cox, K. R., Geuss, M. N., Zaroukian, E. G., &amp; Morris, K. M. (2021a). The validity of situation awareness for performance: A meta-analysis. <em>Theoretical Issues in Ergonomics Science</em>, 1&ndash;24. <code style="white-space: pre;">https://doi.org/10.1080/1463922X.2021.1921310</code>
</p>
<p>Supplemental materials: <code style="white-space: pre;">https://www.tandfonline.com/doi/suppl/10.1080/1463922X.2021.1921310/suppl_file/ttie_a_1921310_sm5524.docx</code>
</p>


<h3>Examples</h3>

<pre>
### copy data into 'dat' and examine data
dat &lt;- dat.bakdash2021
head(dat[c(1,2,6,8:12)])

## Not run: 
#start.time &lt;- Sys.time()

### load metafor
library(metafor)

### multilevel meta-analytic model to get the overall pooled effect
res.overall &lt;- rma.mv(es.z, vi.z, mods = ~ 1,
                      random = ~ 1 | SampleID / Outcome,
                      data = dat,
                      test = "t")
res.overall

### get prediction interval
predict(res.overall)

### cluster-robust variance estimation (CRVE) / cluster-robust inference
res.overall.crve &lt;- robust(res.overall, cluster = SampleID)
res.overall.crve

### get prediction interval
res.overall.crve.pred &lt;- predict(res.overall.crve)
res.overall.crve.pred

### multilevel meta-analytic model for SA measures
res.sa &lt;-  rma.mv(es.z, vi.z, mods = ~ SA.measure.type - 1,
                  random = ~ 1 | SampleID / Outcome,
                  data = dat,
                  test = "t")
res.sa

### cluster-robust variance estimation (CRVE) / cluster-robust inference
res.sa.crve &lt;- robust(res.sa, cluster = SampleID)
res.sa.crve

### profile likelihood plots
par(mfrow=c(2,1))
profile(res.sa.crve, progbar = FALSE)

### format and combine output of meta-analytic models for the forest plot
all.z        &lt;- c(res.sa.crve$beta,            # SA measures
                  res.overall.crve$beta,       # pooled effect for confidence interval (CI)
                  res.overall.crve$beta)       # pooled effect for prediction interval (PI)

all.ci.lower &lt;- c(res.sa.crve$ci.lb,           # SA measures
                  res.overall.crve.pred$ci.lb, # pooled effect, lower CI
                  res.overall.crve.pred$pi.lb) # pooled effect, lower PI

all.ci.upper &lt;- c(res.sa.crve$ci.ub,           # SA measures
                  res.overall.crve.pred$ci.ub, # pooled effect, upper CI
                  res.overall.crve.pred$pi.ub) # pooled effect, upper PI

### note: there is no p-value for the PI
all.pvals  &lt;- c(res.sa.crve$pval, res.overall.crve$pval)
all.labels &lt;- c(sort(unique(dat$SA.measure.type)), "Overall", "95% Prediction Interval")

### function to round p-values for the forest plot
pvals.round &lt;- function(input) {
  input &lt;- ifelse(input &lt; 0.001, "&lt; 0.001",
           ifelse(input &lt; 0.01, "&lt; 0.01",
           ifelse(input &lt; 0.05 &amp; input &gt;= 0.045, "&lt; 0.05",
           ifelse(round(input, 2) == 1.00, "0.99",
           sprintf("%.2f", round(input, 2))))))}

all.pvals.rounded &lt;- pvals.round(all.pvals)

### forest plot
plot.vals &lt;- data.frame(all.labels, all.z, all.ci.lower, all.ci.upper)

par(mfrow=c(1,1), cex = 1.05)
forest(plot.vals$all.z,
       ci.lb = plot.vals$all.ci.lower,
       ci.ub = plot.vals$all.ci.upper,
       slab  = plot.vals$all.labels,
       psize = 1,
       efac = 0, xlim = c(-1.8, 2.5), clim = c(-1, 1),
       transf = transf.ztor, # transform z to r
       at = seq(-0.5, 1, by = 0.25),
       xlab = expression("Correlation Coefficient"~"("*italic('r')*")"),
       main = "\n\n\nSA Measures",
       ilab = c(all.pvals.rounded, ""), ilab.xpos = 2.45, ilab.pos = 2.5,
       digits = 2, refline = 0, annotate = FALSE)

### keep trailing zero using sprintf
output &lt;- cbind(sprintf("%.2f", round(transf.ztor(plot.vals$all.z), 2)),
                sprintf("%.2f", round(transf.ztor(plot.vals$all.ci.lower), 2)),
                sprintf("%.2f", round(transf.ztor(plot.vals$all.ci.upper), 2)))

### alignment kludge
annotext &lt;- apply(output, 1, function(x) {paste0("  ", x[1], " [", x[2],", ", x[3], "]")})
text( 1.05, 12:1, annotext, pos = 4, cex = 1.05)
text(-1.475, 14.00, "SA Measure", cex = 1.05)
text( 2.30,  14.00, substitute(paste(italic('p-value'))), cex = 1.05)
text( 1.55,  14.00, "Correlation [95% CI]", cex = 1.05)
abline(h = 1.5)

### black polygon for overall mean CIs
addpoly(all.z[11], ci.lb = all.ci.lower[11], ci.ub = all.ci.upper[11],
        rows = 2, annotate = FALSE, efac = 1.5, transf = transf.ztor)

### white polygon for PI
addpoly(all.z[12], ci.lb = all.ci.lower[12], ci.ub = all.ci.upper[12],
        rows = 1, col = "white", border = "black",
        annotate = FALSE, efac = 1.5, transf = transf.ztor)

par(mfrow=c(1,1), cex = 1) # reset graph parameters to default

### confidence intervals for the variance components
re.CI.variances &lt;- confint(res.overall)
re.CI.variances

sigma1.z &lt;- data.frame(re.CI.variances[[1]]["random"])
sigma2.z &lt;- data.frame(re.CI.variances[[2]]["random"])

### fit model using alternative multivariate parameterization
res.overall.alt &lt;- rma.mv(es.z, vi.z, mods = ~ 1,
                          random = ~ factor(Outcome) | factor(SampleID),
                          data = dat,
                          test = "t")

### confidence intervals for the total amount of heterogeneity variance component
res.overall.alt.tau &lt;- confint(res.overall.alt, tau2=1)$random

### I^2: http://www.metafor-project.org/doku.php/tips:i2_multilevel_multivariate
W &lt;- diag(1/dat$vi.z)
X &lt;- model.matrix(res.overall)
P &lt;- W - W %*% X %*% solve(t(X) %*% W %*% X) %*% t(X) %*% W

### I^2 (variance due to heterogeneity): 61%
I2 &lt;- 100 * res.overall.alt$tau2 /
      (res.overall.alt$tau2 + (res.overall$k-res.overall$p)/sum(diag(P)))
I2

### 95% CI for I^2 using uncertainty around tau^2
I2.CI.lb &lt;- 100 * res.overall.alt.tau[1,2] /
            (res.overall.alt.tau[1,2] + (res.overall$k-res.overall$p)/sum(diag(P)))
I2.CI.lb

I2.CI.ub &lt;- 100 * res.overall.alt.tau[1,3] /
            (res.overall.alt.tau[1,3] + (res.overall$k-res.overall$p)/sum(diag(P)))
I2.CI.ub

### total amount of heterogeneity (tau)
sqrt(res.overall.alt$tau2)

### heterogeneity table
table.heterogeneity &lt;- data.frame(matrix(ncol = 3, nrow = 4))
colnames(table.heterogeneity) &lt;- c("Parameter Value",
                                   "Lower 95% CI",
                                   "Upper 95% CI")
rownames(table.heterogeneity) &lt;- c("Tau (Total)",
                                   "Tau1 (Between paper)",
                                   "Tau2 (Within paper)",
                                   "I2 (%)")

table.heterogeneity[1,] &lt;- res.overall.alt.tau[2,]
table.heterogeneity[2,] &lt;- sigma1.z[2,]
table.heterogeneity[3,] &lt;- sigma2.z[2,]
table.heterogeneity[4,] &lt;- c(I2, I2.CI.lb, I2.CI.ub)

round(table.heterogeneity, 2)

#end.time &lt;- Sys.time()
#end.time - start.time


## End(Not run)
</pre>

<hr /><div style="text-align: center;">[Package <em>metadat</em> version 1.2-0 <a href="00Index.html">Index</a>]</div>
</div></body></html>
